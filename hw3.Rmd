---
title: "HW3"
author: "Yuyu Fan"
date: "04/03/2020"
output: word_document
---

## Problem 5.7
 1)  5.19 is a model of parallel regressions, the slope is β1, the intercepts are β0,β0 + β2, β0 + β3 for each level of F
 2)  5.20 is a model of common intercepts, the slopes are β1,β1 + β12, β1 + β13 for each level of F, the intercept is β0
 3)  5.21 is a model of common intercepts, the slopes are β1,β1 + β12, β1 + β13 for each level of F, the intercept is β0, and three lines cross at (x1 = δ; y = β0)


## Problem 5.8

```{r }
library(lattice)
library(alr4)
data("cakes")
attach(cakes)
```

```{r}
fit1<-lm(Y~X1*X2+I(X1^2)+I(X2^2))
summary(fit1)
```
So the significance levels for the quadratic terms and the interaction are all less than 0.005
```{r}
fit2<-lm(Y~X1*X2*block+I(X1^2)+I(X2^2))
summary(fit2)
```
 1) the block effect and it's interaction with X2 are not significant, but it has a significant interaction effect with X1
 2) the R-squared is as large as 0.9831, which indicates our model is a good fit
 3) the p-value for F-test is small, which shows that the linear relationship between the response and some of predictors is significant
 
## Problem 7.10
```{r}
data("fuel2001")
attach(fuel2001)
## usual ols estimate
Dlic <- 1000* Drivers/Pop
logMiles <-log(Miles, base=2)
Fuel <- 1000* FuelC/Pop
fit3<- lm(Fuel~Tax+Dlic+Income+logMiles)
yhat<-fit3$fitted.values
ehat<-fit3$residuals
detach(fuel2001)
```



```{r}
## bootstrap
B<-999
n<-51
beta.boot<- matrix(0,5,B)
for(j in 1:5){
  for(i in 1:999){
    id<-sample(1:n,n,replace = T)
    fuel.temp= fuel2001[id,]
    attach(fuel.temp)
    Dlic <- 1000* Drivers/Pop
    logMiles <-log(Miles, base=2)
    Fuel <- 1000* FuelC/Pop
    fit4<- lm(Fuel~Tax+Dlic+Income+logMiles,data = fuel.temp)
    beta.boot[j,i]<-summary(fit4)[["coefficients"]][j]
    detach(fuel.temp)
  }
}

```

```{r}
b<- matrix(0,5,2)
par(mfrow=c(2,3),mar=c(4,3,3,4)+.1, mgp=c(2,1,0))
for(i in 1:5){
  a<-sort(beta.boot[i,])
  b[i,]=quantile(a,c(0.025,0.975))
  hist(beta.boot[i,])
}
confint(fit3)
b
```
## 7.10.1
 From above table, we can see that the bootstrap results vaires a lot from OLS estimates
## 7.10.2
 1) From above histograms, it's clear that histograms appear to be skewed and don't strictly follow normal distribution.
 2) This may due to the randomness of sampling
 3) The large sample normal theory may not apply to this data set.
 
 
## Problem 7.11
```{r}
data(cakes)
attach(cakes)
## delta method
yhat<-fit1$fitted.values
ehat<-fit1$residuals
param.names<- c("b0","b1","b2","b3","b4","b5")
x1.max<-"(b2*b5-2*b1*b4)/(4*b3*b4-b5^2)"
x2.max<-"(b1*b5-2*b2*b3)/(4*b3*b4-b5^2)"
a<-deltaMethod(fit1,x1.max,parameterNames = param.names)
b<-deltaMethod(fit1,x2.max,parameterNames = param.names)
a
b
```


## bootstrap
```{r}
B<-999
n<-14
x2max.boot<-rep(0,B)
for (i in 1:B){
  id <-sample(1:n,n,replace = TRUE)
  yboot<-cakes$Y[id]
  fit5<-lm(yboot~X1+X2+I(X1^2)+I(X2^2)+X1:X2,data=cakes)
  c<-summary(fit5)[["coefficients"]]
  x2max.boot[i]=(c[2]*c[6]-2*c[3]*c[4])/(4*c[4]*c[5]-c[6]^2)
}
x1max.boot<-rep(0,B)
for (i in 1:B){
  id <-sample(1:n,n,replace = TRUE)
  yboot<-cakes$Y[id]
  fit5<-lm(yboot~X1+X2+I(X1^2)+I(X2^2)+X1:X2,data=cakes)
  c<-summary(fit5)[["coefficients"]]
  x1max.boot[i]=(c[3]*c[6]-2*c[2]*c[5])/(4*c[4]*c[5]-c[6]^2)
}
mean(x2max.boot)
mean(x1max.boot)
sqrt(var(x1max.boot))
sqrt(var(x2max.boot))
```










































